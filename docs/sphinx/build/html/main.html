
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Features &#8212; Deep-Framework  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/classic.css" />
    
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">Deep-Framework  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Features</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="features">
<h1>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Can handle multiple video streams from IP cameras and webcams.</p></li>
<li><p>A frame-skipping policy which ensures a real-time behavior by always processing the latest available frame</p></li>
<li><p>Algorithms execution can be distributed across multiple nodes in a cluster.</p></li>
<li><p>Can create multiple worker for every algorithm.</p></li>
<li><p>Every algorithm can be executed in CPU and GPU modes.</p></li>
<li><p>Results and performance stats available via a <a class="reference external" href="https://en.wikipedia.org/wiki/Server-sent_events">Server-Sent Event (SSE)</a> API.</p></li>
<li><p>Can stream resulting data and input video to any web application via <a class="reference external" href="https://en.wikipedia.org/wiki/WebRTC">WebRTC</a>. It can also handle the video stream provided by a client web app via WebRTC.</p></li>
<li><p>It’s possibile to develop and deploy your own detector. See <a class="reference internal" href="develop.html#detector-devel-label"><span class="std std-ref">How to develop a Detector</span></a>.</p></li>
<li><p>It’s possibile to develop and deploy your own descriptor. See <a class="reference internal" href="develop.html#descriptor-devel-label"><span class="std std-ref">How to develop a Descriptor</span></a>.</p></li>
</ul>
</section>
<section id="architecture">
<h1>Architecture<a class="headerlink" href="#architecture" title="Permalink to this headline">¶</a></h1>
<figure class="align-default">
<img alt="architecture scheme" src="_images/schemes.png" />
</figure>
<p>The architecture of Deep Framework is composed by the following generic
components:</p>
<ul class="simple">
<li><p><strong>Stream Manager</strong>: establishes the connection with the video source in order to grab the individual frames and send them, together with a timestamp, to the processing components. It also gets the results from the collectors and stream video and data to any WebRTC peer.</p></li>
<li><p><strong>Detector</strong>: this component is responsible for extracting the coordinates of an object in an image and for tracking it along all received images. The object could be an entity that is depicted in a particular region of the image or in the entire image.</p></li>
<li><p><strong>Broker</strong>: receives data from the Detector and distributes them across all the instances of the Descriptor.</p></li>
<li><p><strong>Descriptor</strong>: carries out the analysis of the ROIs and/or coordinates, retrieved by the Detector, in order ton extract information about objects and/or their trajectories.</p></li>
<li><p><strong>SubCollector</strong>: it aggregates the results obtained by the workers instantiated for each Descriptor.</p></li>
<li><p><strong>Collector</strong>: for every result coming from Detector (objects coordinates, identifiers), it produces an output message aggregating the latest available results obtained from Sub Collectors.</p></li>
<li><p><strong>Monitor</strong>: is connected with all pipeline components and receives and aggregates from them their operating metrics.</p></li>
<li><p><strong>Server</strong>: provides results and stats via a SSE API. It also act as a WebRTC signaling server and provides the demo web app.</p></li>
</ul>
</section>
<section id="getting-started">
<h1>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h1>
<section id="hardware-requirements-for-a-gpu-node">
<h2>Hardware requirements for a GPU node:<a class="headerlink" href="#hardware-requirements-for-a-gpu-node" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>CPU Intel® Core™ i7 CPU &#64; 2.7GHz</p></li>
<li><p>GPU Nvidia with Pascal microarchitecture. Recommended feature: 3584
CUDA core, 12 GBs GPU GDDR5X e 480 GB/s (examples: TITAN X, GeForce
GTX 1080 Ti);</p></li>
<li><p>16 GB RAM;</p></li>
</ul>
</section>
<section id="hardware-requirements-for-a-cpu-node">
<h2>Hardware requirements for a CPU node:<a class="headerlink" href="#hardware-requirements-for-a-cpu-node" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>CPU Intel® Core™ i7 CPU &#64; 2.7GHz</p></li>
<li><p>16 GB RAM;</p></li>
</ul>
</section>
<section id="software-requirements">
<h2>Software requirements:<a class="headerlink" href="#software-requirements" title="Permalink to this headline">¶</a></h2>
<p>Operating system:</p>
<ul class="simple">
<li><p>Ubuntu 16.04 &lt;= version &lt;= 18.04</p></li>
<li><p>macOS version &gt;= 10.12 Sierra (<strong>ONLY FOR A SINGLE NODE CLUSTER IN CPU MODE</strong>)</p></li>
</ul>
<p>Software:</p>
<ul class="simple">
<li><p>python 3.7</p></li>
<li><p>pip 3</p></li>
<li><p>git LFS</p></li>
<li><p>nvidia-driver &gt;= 384.130</p></li>
<li><p>Docker 18.03.1-ce</p></li>
<li><p>Docker Compose 1.23.1</p></li>
<li><p>nvidia-docker 2 (2.0.3+docker18.03.1-1)</p></li>
<li><p>nvidia-container-runtime 2 (2.0.0+docker18.03.1-1)</p></li>
</ul>
<p>These softwares must be installed on each node of the cluster.</p>
</section>
<section id="installing">
<h2>Installing<a class="headerlink" href="#installing" title="Permalink to this headline">¶</a></h2>
<p>Deep-Framework can be deployed on a single node cluster or in a multi
node cluster. Make sure every node is accessible via SSH. Before
installation check disk space usage stats of your Docker installation.
Deep Framework required al least 60 GB of free space on your disk.</p>
<p>Software dependencies:</p>
<ol class="arabic simple">
<li><p>Install python 3 (at least 3.7 version).</p></li>
<li><p>Install pip3.</p></li>
<li><p>Install <a class="reference external" href="https://github.com/git-lfs/git-lfs/wiki/Installation">git LFS</a>.</p></li>
<li><p>Install nvidia-driver (at least 384.130 version).</p></li>
<li><p>Install <a class="reference external" href="https://docs.docker.com/install/linux/docker-ce/ubuntu/">Docker</a> (at least 18.03.1-ce version but lower than 19 version).</p></li>
<li><p>Install <a class="reference external" href="https://docs.docker.com/compose/install/">Docker Compose</a> (at least 1.23.1 version).</p></li>
<li><p>Install <a class="reference external" href="https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0)">nvidia-docker 2 and nvidia-container-runtime2</a> (follow instructions in order to install the proper version according to Docker’s one).</p></li>
<li><p>Clone the repository.</p></li>
<li><p>Install software dependencies with the following command: <code class="docutils literal notranslate"><span class="pre">$</span> <span class="pre">pip3</span> <span class="pre">install</span> <span class="pre">-r</span> <span class="pre">requirements.txt</span></code>.</p></li>
<li><p>In order to setup Face Recognition algorithm, follow these instructions <a class="reference internal" href="face_recognition.html#face-recog-label"><span class="std std-ref">Face Recognition Setup</span></a>.</p></li>
</ol>
<p>Deep-Framework can be deployed on a single node cluster or in a multi node cluster. Make sure every node is accessible via SSH.</p>
</section>
</section>
<section id="running">
<h1>Running<a class="headerlink" href="#running" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p>Starting Deep-Framework:</p></li>
</ul>
<p>Deep-Framework starting is guided by a CLI procedure. You’ll be prompted
to input some information about Deep Framework infrastructure settings
and video analyzing parameters. Deep Framework settings are related to
the cluster configuration (ip address, user, etc. of each of node in the
cluster). Video analyzing parameters are related to video source, max
delay you’ll accept to get your results, stats interval generation and
the algorithms you’ll want to execute with relative execution mode
(cpu/gpu). You can start this procedure with the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python3 main.py
</pre></div>
</div>
<p>If you want to run Deep-Framework with the last configuration used, type the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python3 main.py -r
</pre></div>
</div>
<ul class="simple">
<li><p>Stopping Deep-Framework:</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python3 rm_services.py
</pre></div>
</div>
</section>
<section id="usage">
<h1>Usage<a class="headerlink" href="#usage" title="Permalink to this headline">¶</a></h1>
<section id="using-the-deep-framework-demo-web-application">
<h2>Using the Deep-Framework Demo Web Application<a class="headerlink" href="#using-the-deep-framework-demo-web-application" title="Permalink to this headline">¶</a></h2>
<p>One of the services that are included in the Deep-Framework once it’s up and running is a demo application that allows to visualize and manage the video stream, the resulting data stream, and the performance of the Deep-Framework services and algorithms from any web browser. This web app can be accessed at <cite>https://&lt;IP_ADDRESS_OF_THE_MAIN_NODE&gt;:8000</cite> and provides three main views:</p>
<blockquote>
<div><ul class="simple">
<li><p><strong>CONTROLS</strong>: Here are the controls for establishing the WebRTC peer connection with the Server, selecting the Stream Manager to peer with, and selecting and starting the video stream. The source of the video stream can be either a IP camera (the camera URL has to be previously defined during the guided CLI starting procedure) or the webcam of the client device.</p></li>
<li><p><strong>DASHBOARD</strong>: This is the panel for monitoring the state and performance of the Deep-Framework services and algorithms.</p></li>
<li><p><strong>VIEWER</strong>: Provides the a user friendly interface for visualizing the video stream and the resulting data. Some results like the face detection boxes, and the yaw and pitch angles are graphically represented as an overlay of the video stream.</p></li>
<li><p><strong>API DOCS</strong>: Provides the API documentation for the specific configuration set by the user.</p></li>
</ul>
</div></blockquote>
</section>
<section id="using-a-custom-web-application">
<h2>Using a custom web application<a class="headerlink" href="#using-a-custom-web-application" title="Permalink to this headline">¶</a></h2>
<p>You can interact directly with the Server and the Stream Manager from your browser-based application by using the <a class="reference external" href="https://github.com/crs4/hyperpeer-js">hyperpeer-js module</a> (Deep-Framework video streaming is based on <a class="reference external" href="http://www.crs4.it/results/technology-catalogue/hyperpeer/">Hyperpeer</a> which in turn is based on <a class="reference external" href="https://en.wikipedia.org/wiki/WebRTC">WebRTC</a>). You can install this javascript library (currently available only through its GitHub repo) and using it in your code using browserify or any other frontend package manager. Here <a class="reference internal" href="custom_app_example.html#custom-web-app"><span class="std std-ref">Custom web app example</span></a> you can find a simplified example that illustrates how to use <a class="reference external" href="https://github.com/crs4/hyperpeer-js">hyperpeer-js</a> for sending the local webcam video stream and get the results as <code class="docutils literal notranslate"><span class="pre">data</span></code> events. See <a class="reference external" href="https://github.com/crs4/hyperpeer-js">hyperpeer-js</a> documentation for more details.</p>
</section>
<section id="using-the-sse-api">
<h2>Using the SSE API<a class="headerlink" href="#using-the-sse-api" title="Permalink to this headline">¶</a></h2>
<p>The web app (either the demo or a custom one) is the main interface for controlling and monitoring the analysis of a video stream with the Deep-Framework. However, it connects to the Stream Manager with a peer-to-peer connection so only one client application can be used at a time. If you need to send the video analysis results to another or many other applications you can use the SSE API which provides multiple endpoints (consider that analysis has been started through the web app first in order to receive any data):</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">/api/stream_&lt;DETECTOR_CATEGORY&gt;</span></code>: there is an endpoint for every detector chosen.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/api/stats</span></code>: it shows functioning statistics about the components running in the pipelines.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">/api/algs</span></code>: it shows running alghorithms.</p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="license">
<h1>License<a class="headerlink" href="#license" title="Permalink to this headline">¶</a></h1>
<p>This project is licensed under the GPL3 License - see the <a class="reference external" href="https://github.com/crs4/deep_framework/blob/master/LICENSE">LICENSE</a> file for details.</p>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Features</a></li>
<li><a class="reference internal" href="#architecture">Architecture</a></li>
<li><a class="reference internal" href="#getting-started">Getting Started</a><ul>
<li><a class="reference internal" href="#hardware-requirements-for-a-gpu-node">Hardware requirements for a GPU node:</a></li>
<li><a class="reference internal" href="#hardware-requirements-for-a-cpu-node">Hardware requirements for a CPU node:</a></li>
<li><a class="reference internal" href="#software-requirements">Software requirements:</a></li>
<li><a class="reference internal" href="#installing">Installing</a></li>
</ul>
</li>
<li><a class="reference internal" href="#running">Running</a></li>
<li><a class="reference internal" href="#usage">Usage</a><ul>
<li><a class="reference internal" href="#using-the-deep-framework-demo-web-application">Using the Deep-Framework Demo Web Application</a></li>
<li><a class="reference internal" href="#using-a-custom-web-application">Using a custom web application</a></li>
<li><a class="reference internal" href="#using-the-sse-api">Using the SSE API</a></li>
</ul>
</li>
<li><a class="reference internal" href="#license">License</a></li>
</ul>

  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/main.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">Deep-Framework  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Features</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2021, Alessandro Sassu, Jose Francisco Saenz-Cogollo.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.0.3.
    </div>
  </body>
</html>